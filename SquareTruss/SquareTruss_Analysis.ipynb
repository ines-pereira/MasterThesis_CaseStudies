{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: Truss Rectangular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS functionalities (to deal with files)\n",
    "import os\n",
    "\n",
    "# Enhanced Iteration capabilities (to use cross-products)\n",
    "import itertools\n",
    "\n",
    "# Data processing packages\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Setup for Processing Data\n",
    "\n",
    "In this section, we define all the global constants that will be used thourought the script. By defining them up here, we are making this notebook purely parametric and reusable for other projects (as long as the folder structure remains the same).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folders Structure\n",
    "base_folder = os.getcwd()\n",
    "results_folder = os.path.join(base_folder, \"algorithms\")\n",
    "indicators_folder = os.path.join(base_folder, \"performance_indicators\")\n",
    "output_folder = \"./output/\"\n",
    "\n",
    "# CSV File Configuration\n",
    "has_header=True\n",
    "files_sep= \",\"\n",
    "file_extension = 'csv'\n",
    "\n",
    "# Optimization Settings\n",
    "runs = [1, 2, 3]\n",
    "nruns = len(runs)\n",
    "max_evals = 600\n",
    "\n",
    "## Problem Definition (in the files) \n",
    "### Variables\n",
    "Material = 3\n",
    "Bar_Radius = 4\n",
    "N_Bars = 5\n",
    "Max_Pyramid_Height = 6\n",
    "\n",
    "vars_cols = [Material, Bar_Radius, N_Bars, Max_Pyramid_Height]\n",
    "\n",
    "### Objectives  \n",
    "Max_Displacement = 7\n",
    "Cost = 8\n",
    "\n",
    "objs_cols = [Max_Displacement, Cost]\n",
    "\n",
    "Time = 0\n",
    "relevant_cols = [Time] + vars_cols + objs_cols \n",
    "\n",
    "## Multi-Objective Optimization Algorithms\n",
    "### Metaheuristics\n",
    "pop_size = 30\n",
    "metaheuristics = [\"SMPSO\", \"OMOPSO\", \"SPEA2\", \"NSGAII\", \"MOEAD\", \"PESA2\"]\n",
    "\n",
    "### Model Based (or metamodel)\n",
    "metamodels_base = [\"RFR\", \"ETR\", \"GPR\"] \n",
    "metamodels_strategies = [\"SPEA2\"]\n",
    "metamodels_algorithms = [f\"{b}_{s}\" for (b, s) in itertools.product(metamodels_base, metamodels_strategies)]\n",
    "\n",
    "# all_algorithms = metaheuristics\n",
    "all_algorithms = metaheuristics + metamodels_algorithms\n",
    "n_algorithms = len(all_algorithms)\n",
    "\n",
    "### Filenames with the results \n",
    "filenames = [f\"{a}_results_0{r}.{file_extension}\" for (r, a) in itertools.product(runs, all_algorithms)]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: verify the file names are what we expected\n",
    "filenames[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input/Output (IO) Methods \n",
    "\n",
    "In this subsection we create the methods that will be responsible for loading the data from the files. To manipulate the data, we will use pandas.DataFrame data structure. This can be easily manipulated and different statistics can be computed on top of these abstractions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_results(filenames, base_folder=results_folder, \n",
    "                 has_header=True, keep_header=False, \n",
    "                 sep=files_sep, usecols=relevant_cols,  \n",
    "                 max_lines=max_evals):\n",
    "    \"\"\"Loads the data from the specified `base_folder` using the `filenames`.\n",
    "    It assumes the filenames\n",
    "    \"\"\"\n",
    "    read_args = { \n",
    "        \"header\": 'infer' if keep_header else None, \n",
    "        \"sep\": sep,\n",
    "        \"usecols\": usecols if usecols else None,\n",
    "        \"skiprows\": 1 if has_header and not keep_header else 0,\n",
    "    }\n",
    "    filepaths = [os.path.join(base_folder, f) for f in filenames]        \n",
    "    if max_lines:\n",
    "        return [pd.read_csv(f, **read_args)[0:max_lines] for f in filepaths]\n",
    "    else:\n",
    "        return [pd.read_csv(f, **read_args) for f in filepaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always confirm whether the results are according to what you expected\n",
    "examples = load_results(filenames, max_lines=max_evals)\n",
    "examples[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x > max_evals, [len(e) for e in examples]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_indices(dfs, run, n_algorithms=n_algorithms):\n",
    "    \"\"\"Returns the dataframes that correspond to the specified `run`. \n",
    "    This assumes that the dataframes are read per run, that means that \n",
    "    if we run two algorithms (SMPSO and SPEA2) for 3 runs each, this \n",
    "    method assumes that it was read in the following order:\n",
    "    \n",
    "    > SMPSO_run1\n",
    "    > SPEA2_run1\n",
    "    > SMPSO_run2\n",
    "    > SPEA2_run2\n",
    "    > SMPSO_run3\n",
    "    > SPEA2_run3\n",
    "    \n",
    "    In that case, this invocation `get_run_indices(dfs, 1, n_algorithms=2)`\n",
    "    will return: \n",
    "        dfs[0:2] \n",
    "    \"\"\"\n",
    "    run -= 1\n",
    "    return dfs[run*n_algorithms:(run+1)*n_algorithms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto Dominance Methods\n",
    "This section contains methods related to the Pareto optimality (or [Pareto Efficiency](https://en.wikipedia.org/wiki/Pareto_efficiency))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **IMPORTANT NOTE**: This function assumes that your problem is a minimization problem for every objective dimension.\n",
    "def weakly_dominates(v0, v1):\n",
    "    \"\"\"Computes whether v0 dominates v1, i.e., whether at least one objective\n",
    "    is better (in this case, smaller) than some other)\n",
    "    \"\"\"\n",
    "    return np.all(v0 <= v1) and np.any(v0 < v1)\n",
    "    \n",
    "# Sanity Check (:\n",
    "print(\"(Expected) True   (Obtained)\", weakly_dominates(np.array([1, 1]), np.array([2, 2])))\n",
    "print(\"(Expected) True   (Obtained)\", weakly_dominates(np.array([2, 1]), np.array([2, 2])))\n",
    "print(\"(Expected) False  (Obtained)\", weakly_dominates(np.array([2, 2]), np.array([1, 1]))) \n",
    "print(\"(Expected) True   (Obtained)\", weakly_dominates(np.array([1, 2]), np.array([2, 2]))) \n",
    "print(\"(Expected) False  (Obtained)\", weakly_dominates(np.array([1, 3]), np.array([3, 1])))\n",
    "print(\"(Expected) False  (Obtained)\", weakly_dominates(np.array([3, 1]), np.array([1, 3]))) \n",
    "print(\"(Expected) False  (Obtained)\", weakly_dominates(np.array([1, 1]), np.array([1, 1])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_dominated(V, dominance=weakly_dominates):\n",
    "    \"\"\"Computes the optimal and non-optimal solutions. \n",
    "    Optimal solutions are called non-dominated and non-optimal \n",
    "    solutions are called denominated.\"\"\"\n",
    "    nsols, nobjs = V.shape\n",
    "    \n",
    "    dominated = np.zeros((nsols, 1))\n",
    "    dominated_by = np.zeros((nsols, 1))\n",
    "    for i in range(nsols):\n",
    "        for j in range(nsols):\n",
    "            if i != j:\n",
    "                if dominance(V[j], V[i]):\n",
    "                    dominated[i] = 1\n",
    "                    dominated_by[i] = j \n",
    "                    break\n",
    "                    \n",
    "    return dominated, dominated_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_isdominated_cols(d, cols=objs_cols):\n",
    "    \"\"\"Adds to the provided dataframe columns for Pareto optimal solution.\"\"\"\n",
    "    df_copy = d.copy()\n",
    "    A = np.array(df_copy[cols])\n",
    "    B, C = get_non_dominated(A)\n",
    "    df_copy[\"isDominated\"] = pd.DataFrame(B, columns=[\"isDominated\"])\n",
    "    df_copy[\"dominatedBy\"] = pd.DataFrame(C, columns=[\"dominatedBy\"])\n",
    "    print(df_copy[\"isDominated\"].value_counts())\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_PF(dfs, drop_cols=relevant_cols, objs_cols=objs_cols):\n",
    "    \"\"\"Computes the combined Pareto front based on a set of input dataframes\"\"\"\n",
    "    all_data = pd.concat(dfs)\n",
    "    if drop_cols:\n",
    "        all_data = all_data.drop_duplicates(drop_cols)\n",
    "    all_data = all_data.reset_index()\n",
    "    return add_isdominated_cols(all_data, cols=objs_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Methods\n",
    "This section contains general purpose methods that can be used in your scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcasting_multi(df, cols, value):\n",
    "    cols = cols if isinstance(cols, (list, tuple)) else [cols]\n",
    "    copy_df = df.copy()\n",
    "    for col in cols:\n",
    "        copy_df[col] = df[col] * value\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcasting_div(df, cols, value):\n",
    "    cols = cols if isinstance(cols, (list, tuple)) else [cols]\n",
    "    copy_df = df.copy()\n",
    "    for col in cols:\n",
    "        copy_df[col] = df[col] / value\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symmetric(df, cols):\n",
    "    \"\"\"Computes the symmetric value of the provided `cols` and returns a \n",
    "    copy of the original dataframe where the values of the specified `cols`\n",
    "    are symmetric.\"\"\"\n",
    "    return broadcasting_multi(df, cols, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unscale(df, cols, minimum, step):\n",
    "    \"\"\"Computes the real value used for the variables during a discrete optimization process.\"\"\"\n",
    "    cols = cols if isinstance(cols, (list, tuple)) else [cols]\n",
    "    copy_df = df.copy()\n",
    "    for col in cols:\n",
    "        copy_df[col] = minimum + step * df[col]\n",
    "    return copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_by_value(dfs, col, value):\n",
    "    \"\"\"Drops the solutions from the provided dataframes based on a column and a value, \n",
    "    changing them inplace.\"\"\"\n",
    "    for df in dfs:      \n",
    "        unfeasible_sols = df.loc[df[col]==value]\n",
    "        df.drop(unfeasible_sols.index, inplace=True)\n",
    "        df.index = range(len(df))\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unfeasibles(dfs):\n",
    "    \"\"\"Drops the unfeasible solutions from the provided dataframes, \n",
    "    changing them inplace.\"\"\"\n",
    "    return drop_by_value(dfs, feasible_col, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfeasible_ratio_iter(pop_size=pop_size):\n",
    "    \"\"\"Computes the unfeasible ratio per `pop_size`.\"\"\"\n",
    "    results = []\n",
    "    for i in range(0, len(df), pop_size):\n",
    "        results.append(df[df[i:i + pop_size] == 'false']['feasible'].count() / pop_size)\n",
    "    iteration = pd.Series(data = range(1, int(len(df) / pop_size) + 1))\n",
    "    ratio = pd.Series(data = results)\n",
    "    ratio_iter = {'Iteration': iteration, 'Ratio Unfeasible': ratio} \n",
    "    return pd.DataFrame(ratio_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_value_iter(df, col_name='hypervolume', iter_size=pop_size):\n",
    "    \"\"\"Iterates the values in the `df` in slices of `iter_size` and \n",
    "    gets the last value.\n",
    "    \"\"\"\n",
    "    return df[iter_size-1:len(df):iter_size][col_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicators_results(results_runs):\n",
    "    \"\"\"Computes the statistics mean and standard deviation for the specified runs. \n",
    "    \n",
    "    It assumes the `results_run` are organized as follows: \n",
    "        results_runs = [indicators_run1, indicators_run2, indicators_run3], \n",
    "    where: \n",
    "        indicators_run{i} = [indicators_alg_1_run_{i}, ..., indicators_alg_m_run_{i}]\n",
    "    \"\"\"\n",
    "    average_res = [] \n",
    "    std_res = [] \n",
    "    \n",
    "    for algorithm_i in range(n_algorithms):\n",
    "        # Get the same algorithm from all runs (assuming they were collected in the same way)\n",
    "        algorithm_results = [r[algorithm_i] for r in results_runs] \n",
    "        average_res += [pd.concat(algorithm_results, axis=1).mean(axis=1)]\n",
    "        std_res += [pd.concat(algorithm_results, axis=1).std(axis=1)]\n",
    "        \n",
    "    return average_res, std_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "In this section, we visualize the data with visual means. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Framework\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "%matplotlib inline\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "try:\n",
    "    import plotly.plotly as py\n",
    "    plotly.tools.set_credentials_file(username='username', api_key='api_key')\n",
    "except: \n",
    "    import chart_studio\n",
    "    import chart_studio.plotly as py\n",
    "    chart_studio.tools.set_credentials_file(username='username', api_key='api_key')\n",
    "    \n",
    "# Print plotly's version\n",
    "plotly.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the functions that create the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors(n, colorscale=\"viridis\"): \n",
    "    colors = plt.get_cmap(colorscale).colors\n",
    "    colors_idx = np.linspace(0, len(colors)-1, n, dtype=int)\n",
    "    \n",
    "    colors = [colors[idx] for idx in colors_idx]\n",
    "    colors_str = [f\"rgb({r}, {g}, {b})\" for (r, g, b) in colors]\n",
    "    return colors_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(data, x=None, y=None, names=all_algorithms, \n",
    "            colorscale=\"viridis\", colors=None, \n",
    "            mode=\"markers\", marker_size=5.5, ln_width=1.5, \n",
    "            layout=None):\n",
    "    \n",
    "    def get_x_y(d): \n",
    "        if isinstance(d, pd.Series):\n",
    "            return np.array(d.index) + 1, d.values\n",
    "        elif isinstance(d, pd.DataFrame):\n",
    "            return d[x], d[y]\n",
    "        else: \n",
    "            return np.arange(len(d)), d      \n",
    "        \n",
    "    # ----------------------------------------------\n",
    "    # Normalize input data\n",
    "    # ----------------------------------------------\n",
    "    data = data if isinstance(data, (list, tuple)) else [data]\n",
    "    colors = get_colors(len(data), colorscale) if colorscale else colors\n",
    "    \n",
    "    # ----------------------------------------------\n",
    "    # Determine the data types of provided inputs\n",
    "    # ----------------------------------------------\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    for d in data:\n",
    "        xx, yy = get_x_y(d)\n",
    "        x_data += [xx]\n",
    "        y_data += [yy]\n",
    "\n",
    "    \n",
    "    traces = []\n",
    "    for (i, (x,y)) in enumerate(zip(x_data, y_data)):\n",
    "        traces += [\n",
    "            go.Scatter(\n",
    "                x = x,\n",
    "                y = y,\n",
    "                mode = mode,\n",
    "                name = names[i],\n",
    "                marker = dict(\n",
    "                    # Markers size\n",
    "                    size = marker_size,\n",
    "                    color=colors[i],\n",
    "                ),\n",
    "                line=dict(\n",
    "                    width=ln_width,\n",
    "                    color=colors[i]\n",
    "            )\n",
    "            )]\n",
    "    \n",
    "    kwargs = {} if not layout else {\"layout\": layout}\n",
    "    fig = go.Figure(data=traces, **kwargs)\n",
    "    return py.iplot(fig, filename='simple_scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default layout for the pareto fronts graphs\n",
    "layout = go.Layout(\n",
    "    template=\"plotly_white\",\n",
    "    autosize=True,\n",
    "    legend=dict(\n",
    "        orientation='h'\n",
    "    ),\n",
    "    # Define axis\n",
    "    xaxis=dict(\n",
    "        autorange=True,\n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "        ticks='',\n",
    "        showticklabels=True,\n",
    "        tickformat='.'\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        autorange=True,        \n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "        ticks='',\n",
    "        showticklabels=True,\n",
    "        tickformat='.'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pareto Front\n",
    "\n",
    "This section contains different functions that explore dataframes having information about the non-dominated and the dominated solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pf(pf, name, x, y, nd_color='rgb(0,0,255)', ln_width=1.5, marker_size=5.5, d_color=None): \n",
    "    traces = []\n",
    "    \n",
    "    # Create the non dominated trace (in a different color, as specified in *nd_color*)\n",
    "    x_pf = pf[pf['isDominated'] == 0][x] \n",
    "    y_pf = pf[pf['isDominated'] == 0][y]\n",
    "    x_pf, y_pf = zip(*sorted(zip(x_pf, y_pf)))\n",
    "    \n",
    "    # Get information about the objectives and variables - relevant for an iteractive PF\n",
    "    info = []\n",
    "    info.extend(vars_cols)\n",
    "    info.extend(objs_cols)\n",
    "    info_pf = np.array(pf[pf['isDominated'] == 0][info])\n",
    "    info_npf = np.array(pf[pf['isDominated'] == 1][info])\n",
    "    \n",
    "    traces += [\n",
    "        go.Scatter(\n",
    "            x = x_pf,\n",
    "            y = y_pf,\n",
    "            mode = 'lines+markers',\n",
    "            name = name + \" NonDominated\",\n",
    "            customdata = info_pf,\n",
    "            opacity=1,\n",
    "\n",
    "            # Layout do marker\n",
    "            marker=dict(\n",
    "                color=nd_color,\n",
    "                size=marker_size\n",
    "            ),\n",
    "            line=dict(\n",
    "                color=nd_color,\n",
    "                width=ln_width\n",
    "            )\n",
    "        )]\n",
    "    \n",
    "    if d_color:\n",
    "        x_npf = pf[pf['isDominated'] == 1][x]\n",
    "        y_npf = pf[pf['isDominated'] == 1][y]\n",
    "        \n",
    "        # Create the dominated trace (in a different color, as specified in *d_color*)\n",
    "        traces +=[\n",
    "            go.Scatter(\n",
    "                x = x_npf,\n",
    "                y = y_npf,\n",
    "                mode = 'markers',\n",
    "                name = name + \" Dominated\",\n",
    "                customdata = info_npf,\n",
    "                opacity=0.55,\n",
    "\n",
    "                # Layout do Marker\n",
    "                marker=dict(\n",
    "                    #color = d_color,\n",
    "                    color = nd_color,\n",
    "                    size = 0.55 * marker_size,\n",
    "                )\n",
    "            )]\n",
    "\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traces(pfs, x, y, draw_dominated=True,\n",
    "               names=all_algorithms, colorscale='viridis', colors=None,\n",
    "               tpf=None, tpf_name=\"Combined_PF\", tpf_color='rgb(0,0,0)', \n",
    "               layout=layout):\n",
    "    \n",
    "    pfs = pfs if isinstance(pfs, (list, tuple)) else [pfs]\n",
    "    names = names if isinstance(names, (list, tuple)) else [names]\n",
    "    n_pfs = len(pfs)\n",
    "    colors = get_colors(n_pfs, colorscale) if colorscale else colors\n",
    "    \n",
    "    traces = []\n",
    "    \n",
    "    if tpf is not None:\n",
    "        traces += create_pf(pf=tpf, name=tpf_name, x=x, y=y, ln_width=4, marker_size=10, nd_color=tpf_color)\n",
    "    \n",
    "    for (i, pf) in enumerate(pfs):\n",
    "        d_color = colors[i] if draw_dominated else None\n",
    "        traces += create_pf(pf=pf, name=names[i], x=x, y=y, nd_color=colors[i], d_color=d_color)\n",
    "\n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    return traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pfs(pfs, x, y, draw_dominated=True,\n",
    "               names=all_algorithms, colorscale='viridis', colors=None,\n",
    "               tpf=None, tpf_name=\"Combined_PF\", tpf_color='rgb(0,0,0)', \n",
    "               layout=layout):\n",
    "    \n",
    "    traces = get_traces(pfs, x, y, draw_dominated, names, colorscale, colors, tpf, tpf_name, tpf_color, layout)\n",
    "    \n",
    "    fig = go.Figure(data=traces, layout=layout)\n",
    "    return py.iplot(fig, filename='algorithms_pfs_per_run')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pareto Front Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_truss = go.Layout(\n",
    "    template=\"plotly_white\",\n",
    "    autosize=True,\n",
    "    # Legend Position\n",
    "    legend=dict(\n",
    "        orientation='h',\n",
    "        x=-0.01,\n",
    "        y=-0.2\n",
    "    ),\n",
    "    \n",
    "    # Define axis\n",
    "    xaxis=dict(\n",
    "        type=\"log\",\n",
    "        title=\"Cost [€]\",\n",
    "        autorange=True, \n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        type=\"log\",\n",
    "        title=\"Maximum Displacement [m]\",\n",
    "        autorange=True, \n",
    "        showgrid=True,\n",
    "        zeroline=False,\n",
    "        showline=True,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read algorithms  \n",
    "dfs = load_results(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!!\n",
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute non_dominated_solutions (per run)\n",
    "pfs = [add_isdominated_cols(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity check!!\n",
    "pfs[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computes combined Pareto Front (optimal solutions found from all the algorithms, all the runs)\n",
    "combined_pf = get_combined_PF(dfs, drop_cols=relevant_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot for all obtained solution (1 single plot for all algorithms, all runs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pfs(pfs, y=Max_Displacement, x=Cost, tpf=combined_pf, names=filenames, \n",
    "           colorscale='plasma', draw_dominated=False, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_pfs(pfs, y=Max_Displacement, x=Cost, tpf=combined_pf, names=filenames,\n",
    "           colorscale='plasma', draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot algorithms per run (3 plot one for each run) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Run 1 \n",
    "dfs_run_1 = get_run_indices(dfs, 1)\n",
    "pfs_run_1 = [add_isdominated_cols(df) for df in dfs_run_1]\n",
    "combined_PF_run_1 = get_combined_PF(pfs_run_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get Run 2 \n",
    "dfs_run_2 = get_run_indices(dfs, 2)\n",
    "pfs_run_2 = [add_isdominated_cols(df) for df in dfs_run_2]\n",
    "combined_PF_run_2 = get_combined_PF(pfs_run_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Run 3 \n",
    "dfs_run_3 = get_run_indices(dfs, 3)\n",
    "pfs_run_3 = [add_isdominated_cols(df) for df in dfs_run_3]\n",
    "combined_PF_run_3 = get_combined_PF(pfs_run_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get All Runs\n",
    "# Before running this run the previous cells (the ones that define dfs_run_{i})\n",
    "pfs_all_runs = []\n",
    "for i in range(n_algorithms):\n",
    "    pf=get_combined_PF([dfs_run_1[i], dfs_run_2[i], dfs_run_3[i]])\n",
    "    pfs_all_runs.append(pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved only from all algorithms of run 1\n",
    "create_pfs(pfs_run_1, y=Max_Displacement, x=Cost, tpf=combined_PF_run_1,\n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved from all runs\n",
    "create_pfs(pfs_run_1, y=Max_Displacement, x=Cost, tpf=combined_pf, \n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved only from all algorithms of run 2\n",
    "create_pfs(pfs_run_2, y=Max_Displacement, x=Cost, tpf=combined_PF_run_2, \n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved from all runs\n",
    "create_pfs(pfs_run_2, x=material_cost, y=sUDI, tpf=combined_pf, \n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved only from all algorithms of run 3\n",
    "create_pfs(pfs_run_3, y=Max_Displacement, x=Cost, tpf=combined_PF_run_3, \n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with combined pareto front retrieved from all runs\n",
    "create_pfs(pfs_run_3, x=material_cost, y=sUDI, tpf=combined_pf, \n",
    "           names=all_algorithms, draw_dominated=True, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with one PF per algorthim, using the information of the 3 runs\n",
    "create_pfs(pfs_all_runs, y=Max_Displacement, x=Cost, tpf=None, names=all_algorithms, \n",
    "           colorscale=None,\n",
    "           colors=['#93e0ed', '#307382', #PSOs colors\n",
    "                   '#2fcce0', '#042780', '#fcb447', '#fcb447', # EAs colors\n",
    "                   '#db3f30', '#8a39db', '#db30b9'], # MBs colors\n",
    "           draw_dominated=False, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create plot with one PF per algorthim, using the information of the 3 runs and with the combined PF\n",
    "create_pfs(pfs_all_runs, y=Max_Displacement, x=Cost, tpf=combined_pf, tpf_color='#3b3b3b',\n",
    "           names=all_algorithms,\n",
    "           colorscale=None,\n",
    "           colors=['#FAA275', '#FF8C61', #PSOs colors\n",
    "                   '#e77b73', '#ce6a85', '#985277', '#5c374c', # EAs colors\n",
    "                   '#218380', '#73d2de', '#a0e0e8'], # MBs colors\n",
    "           draw_dominated=False, layout=layout_truss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Performance Indicators per iteration\n",
    "After running the optimization processes for the 10 algorithms for 3 runs, we computed their __Hypervolume (HV)__ \\[1\\], as well as other indicators, such as the __Overall Non-dominated Vector Generated (ONVG)__ \\[2\\] and the __Set Spacing (SS)__ \\[3\\]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = load_results(filenames, base_folder=indicators_folder, has_header=True, keep_header=True, usecols=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs[0].head() # Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs_run_1 = get_run_indices(idfs, 1)\n",
    "idfs_run_2 = get_run_indices(idfs, 2)\n",
    "idfs_run_3 = get_run_indices(idfs, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypervolume_run_1 = [get_last_value_iter(df, col_name='hypervolume') for df in idfs_run_1]\n",
    "hypervolume_run_2 = [get_last_value_iter(df, col_name='hypervolume') for df in idfs_run_2]\n",
    "hypervolume_run_3 = [get_last_value_iter(df, col_name='hypervolume') for df in idfs_run_3]\n",
    "hypervolume_per_run = [hypervolume_run_1, hypervolume_run_2, hypervolume_run_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onvg_run_1 = [get_last_value_iter(df, col_name='onvg') for df in idfs_run_1]\n",
    "onvg_run_2 = [get_last_value_iter(df, col_name='onvg') for df in idfs_run_2]\n",
    "onvg_run_3 = [get_last_value_iter(df, col_name='onvg') for df in idfs_run_3]\n",
    "onvg_per_run = [onvg_run_1, onvg_run_2, onvg_run_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(hypervolume_run_1, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(onvg_run_1, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(hypervolume_run_2, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(onvg_run_2, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(hypervolume_run_3, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(onvg_run_3, mode='lines+markers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Indicators: Average and Standard Deviation across the 3 runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default layout for the pareto fronts graphs\n",
    "layout_indicators = lambda x: go.Layout(\n",
    "        template=\"plotly_white\",\n",
    "        autosize=False,\n",
    "        # Define plot size\n",
    "        width=850,\n",
    "        height=500,\n",
    "        # Legend Position\n",
    "        legend=dict(\n",
    "            orientation='h',\n",
    "            x=0.02,\n",
    "            y=-0.25\n",
    "        ),\n",
    "        # Define axis\n",
    "        xaxis=dict(\n",
    "            title=\"Number of Evaluations\",\n",
    "            range=[1, 630],\n",
    "            # autorange=True,\n",
    "            showgrid=True,\n",
    "            zeroline=True,\n",
    "            showline=True,\n",
    "            ticks='',\n",
    "            showticklabels=True,\n",
    "            tickvals = np.array(range(pop_size, 600, pop_size)),\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title=x,\n",
    "            showgrid=True,\n",
    "            zeroline=False,\n",
    "            showline=True,\n",
    "            ticks='',\n",
    "            showticklabels=True\n",
    "        )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypervolume Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypervolume_avg, hypervolume_std = indicators_results(hypervolume_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=scatter(hypervolume_avg, mode='lines+markers',\n",
    "        layout=layout_indicators('Hypervolume'),\n",
    "        colorscale=None,\n",
    "        colors=['#ffb300', '#FF8C61', #PSOs colors\n",
    "                '#994b45', '#d96483', '#c78ba1', '#5c374c', # EAs colors\n",
    "                '#11706d', '#42c7c3', '#a0e0e8'], # MBs colors\n",
    "       )\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(hypervolume_std, mode='lines+markers', layout=layout_indicators('Hypervolume'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONVG Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onvg_avg, onvg_std = indicators_results(onvg_per_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(onvg_avg, mode='lines+markers',\n",
    "        layout=layout_indicators('ONVG'),\n",
    "        colorscale=None,\n",
    "         colors=['#ffb300', '#FF8C61', #PSOs colors\n",
    "                '#994b45', '#d96483', '#c78ba1', '#5c374c', # EAs colors\n",
    "                '#11706d', '#42c7c3', '#a0e0e8'], # MBs colors\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(onvg_std, mode='lines+markers', layout=layout_indicators('ONVG'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__References__\n",
    "\n",
    "\\[1\\] Russo, L. M. S., & Francisco, A. P. (2014). _Extending quick hypervolume_. Journal of Heuristics, 22(3), 245–271.\n",
    "\n",
    "\\[2\\] Veldhuizen, D. V. (1999). _Multi Objective evolutionary algorithms: Classifications, Analysis, New Innovations. Multi Objective evolutionary algorithms_. Air Force Institute of Technology, Wright Patterson, Ohio.\n",
    "\n",
    "\\[3\\] Schott, J. R. (1995). _Fault Tolerant Design Using Single and Multicriteria Genetic Algorithm Optimization_. Massachusetts Institute of Technology, Boston, MA."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "238px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
